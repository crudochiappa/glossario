# glossario
Affidabilità: si caratterizza come coerenza interna quando si riferisce a quanto gli item che formano una scala sono consistenti fra loro. L’affidabilità è di solito calcolata o utilizzando l’affidabilità split-half, in cui il punteggio di metà degli item è correlato con il punteggio dell’altra metà (correggendo per la lunghezza della scala), oppure utilizzando l’alfa di Cronbach, che è una media di tutte le possibili affidabilità split-half. Un metodo distinto per il calcolo dell’affidabilità è il test-retest, che misura la consistenza di una scala nel tempo.

Affidabilità split-half: correlazione fra le due metà di una scala aggiustate per il numero di variabili in ciascuna scala.

Affidabilità test-retest: la correlazione fra i punteggi ottenuti in una prova con quelli ottenuti nella stessa prova o in una prova simile somministrata successivamente.

Alfa di Cronbach: misura di quanto i casi rispondano in modo simile o coerente a tutte le parti o variabili che costituiscono una scala.

Analisi dei cluster: insieme di tecniche che identificano gruppi di variabili o casi che hanno caratteristiche in comune. Nessuna analisi dei cluster viene descritta in questo volume, essendo allo stato attuale poco utilizzate in psicologia. L’analisi fattoriale, trattata in questo volume, viene spesso utilizzata per uno scopo analogo.

Analisi della covarianza (ANCOVA): opzione dell’analisi della varianza in cui i punteggi della variabile dipendente sono aggiustati in funzione di una o più covariate. Per esempio, le differenze nei punteggi ottenuti nel campione possono essere corrette per l’età dei soggetti.

Analisi della varianza (ANOVA): un test statistico generale per il confronto di medie di una variabile dipendente. Può considerare uno o più criteri di classificazione (chiamati fattori o variabili indipendenti). L’ANOVA è un test fondamentale nella valutazione di dati sperimentali.

Analisi della varianza multivariata (MANOVA): tipo di analisi della varianza in cui sono presenti più variabili dipendenti correlate fra loro. La MANOVA valuta le differenze fra i gruppi sull’insieme combinato delle variabili dipendenti.

Analisi delle componenti principali: metodo di base dell’analisi fattoriale che parte assegnando a ogni variabile una varianza pari a 1, senza alcun aggiustamento per le comunalità. Probabilmente più utile nelle situazioni in cui la matrice di correlazione ha coefficienti alti, cosa non comune nella ricerca psicologica.

Analisi discriminante: tecnica statistica per variabili quantitative che, sulla base di un insieme di variabili, massimizza le differenze fra due o più gruppi di soggetti. A tale scopo genera dei pesi da attribuire a ciascuna variabile.

Analisi fattoriale confermativa: verifica se e quanto un particolare modello o struttura fattoriale si adatta in modo soddisfacente a un nuovo insieme di dati.

Analisi fattoriale esplorativa: forma base dell’analisi fattoriale che dalla matrice di correlazione individua le componenti di maggior dimensione usando le combinazioni pesate delle variabili in studio. Identifica le combinazioni che possono essere generate da una o più variabili generatrici, dette fattori.

Analisi log-lineare: tecnica statistica per variabili categoriche che costituisce sostanzialmente un’estensione del chi-quadro quando si hanno tre o più variabili categoriche.

ANOVA a disegno fattoriale: analisi della varianza con due o più fattori e tutte le loro possibili combinazioni.

ANOVA a disegno misto: ANOVA in cui si hanno sia fattori di ripetizione o correlate sia gruppi indipendenti.

ANOVA per misure ripetute: analisi della varianza basata su uno o più fattori correlati.

Associazione: relazione fra due variabili.

Bimodale: distribuzione di frequenza con due picchi di frequenza (mode).

Bivariata: analisi che riguarda due variabili, distinta dall’univariata che riguarda invece una sola variabile.

Blocco: sottoinsieme di variabili che vengono analizzate assieme in un’analisi a sequenza di blocchi.

Bootstrap: metodo di creazione di una distribuzione campionaria dal campione iniziale che viene riprodotto più volte per simulare la popolazione generale. Questo permette un campionamento ripetuto, quindi il calcolo della distribuzione campionaria per i diversi tipi di statistica.

Calcola: in SPSS finestra di dialogo che permette di creare nuove variabili trasformando quelle originali. Per esempio è possibile creare una variabile somma di altre variabili.

Campione: selezione di un sottoinsieme dei punteggi relativi a una variabile. Non si può garantire che il campione sia rappresentativo della popolazione ma, se viene scelto casualmente, si suppone non ci sia differenza sistematica fra campione e popolazione.

Caso: l’unità elementare nella raccolta dati vista come individuo o organizzazione.

Coefficiente beta: coefficiente di regressione standardizzato nella regressione multipla. Nella regressione lineare semplice corrisponde al coefficiente di regressione.

Coefficiente di correlazione: indice che fornisce la misura e la direzione dell’associazione lineare fra due variabili.

Coefficiente di correlazione di Spearman: misura del grado e della direzione dell’associazione tra due variabili ordinali.

Coefficiente di correlazione multiplo r: coefficiente di correlazione che lega un punteggio (A) con due o più altri punteggi (B, C) combinati fra loro. Tale coefficiente è usato particolarmente nella regressione multipla come misura della correlazione tra un insieme di predittori e la variabile dipendente.

Coefficiente di determinazione r2: corrisponde al quadrato del coefficiente di correlazione di Pearson. Un coefficiente di correlazione di 0.4 ha un coefficiente di determinazione di 0.16. Utilizzato al posto del coefficiente di correlazione perché indica la percentuale di variabilità totale spiegata dal modello regressivo.

Coefficiente di regressione: il coefficiente per cui moltiplicare il predittore per avere il valore della variabile dipendente.

Coefficienti non standardizzati: coefficienti che vanno utilizzati con i punteggi grezzi (da distinguere dai coefficienti standardizzati).

Coefficienti standardizzati: coefficienti dei predittori in un’equazione i cui punteggi sono stati standardizzati.

Comunalità: la parte di varianza che, in un’analisi, una variabile condivide con altre variabili. Si distingue dalla varianza errore e dalla varianza specifica (relativa a una sola variabile). Viene considerata soprattutto nell’analisi fattoriale.

Condizione: uno dei gruppi nell’ANOVA o nel t-test.

Confronti appaiati: confronto a coppia fra tutte le medie ottenute.

Confronti non pianificati: confronti fra alcuni gruppi che non erano stati pianificati prima di raccogliere i dati ma che si decidono in base ai risultati ottenuti.

Confronti pianificati: confronti parziali decisi a priori sulla base delle conoscenze o dello scopo della ricerca.

Connessione: linea del grafo che rappresenta la relazione fra due variabili.

Correlazione bivariata: correlazione fra due variabili.

Correlazione parziale: correlazione fra predittore e variabile dipendente quando gli effetti degli altri predittori sulla variabile dipendente e sul predittore sono stati eliminati.

Correlazione punto-seriale: correlazione fra una variabile dicotomica e una variabile quantitativa.

Correlazione semi-parziale: correlazione fra predittore e variabile dipendente dopo che gli effetti degli altri predittori sulla variabile dipendente sono stati eliminati.

Correzione di Bonferroni: metodo di aggiustamento dei valori di significatività in ragione del numero di confronti che vengono effettuati indipendentemente sugli stessi dati.

Correzione di Yates: un obsoleto metodo di aggiustamento del valore del chi-quadro nelle tabelle 2 × 2 per migliorare l’approssimazione alla distribuzione chi-quadro.

Covarianza: la varianza che due o più variabili quantitative condividono. Viene calcolata in modo analogo alla varianza ma, anziché elevare al quadrato gli scarti dalla media, si calcola il prodotto dello scarto dalla media della variabile X per lo scarto dalla media della variabile Y.

Covariata: variabile che correla con le variabili oggetto principale dello studio. Nell’analisi della covarianza rappresenta il fattore indesiderato di cui si cerca di eliminare l’effetto.

Curtosi: misura di quanto una curva a campana sia più piatta o più appuntita di una curva gaussiana.

Dati a intervallo: dati rappresentati con una scala in cui la distanza fra punti adiacenti è assunta costante ma in cui non è presente nessun valore di zero come punto di riferimento.

Dati ordinali: valori in cui l’unica informazione è relativa all’ordine, al fatto che un valore viene prima o dopo un altro.

Deviazione: normalmente intesa come la differenza fra un punteggio singolo e la media dei punteggi.

Deviazione standard: concettualmente la media degli scarti dalla media.

Dicotomica: variabile nominale (categoria) con due soli valori possibili. Il genere (maschio/femmina) è l’esempio più comune.

Dimensione dell’effetto: misura della forza della relazione statistica fra più variabili. Frequentemente utilizzata nella meta-analisi. Il coefficiente di correlazione di Pear­son è un caso abbastanza comune di misura della dimensione dell’effetto. Di frequente utilizzo è anche il d di Cohen. Il coefficiente di correlazione ha il vantaggio di essere un parametro largamente noto e di cui è facile capire il significato.

Disegni controbilanciati: se alcuni soggetti sono posti prima nella condizione A e successivamente nella condizione B, per controbilanciare l’effetto tempo o l’effetto sequenza altri soggetti devono essere prima posti nella condizione B e poi in quella A.

Disegno a gruppi indipendenti: disegno in cui i diversi casi sono assegnati a diversi gruppi o condizioni indipendenti.

Disegno a misure ripetute: disegno in cui le variabili dipendenti sono misurate sugli stessi soggetti in diverse condizioni sperimentali.

Disegno correlato: disegno in cui i partecipanti vengono valutati in più condizioni sperimentali. È il caso in cui i partecipanti fungono da controllo di se stessi. Più raramente viene riferito come disegno in cui i soggetti sono appaiati sulla base del valore di una variabile di controllo. Se la variabile di controllo è correlata con la variabile dipendente, anche questo disegno può essere considerato correlato.

Disegno correlato fattoriale: disegno nel quale due o più variabili indipendenti o predittori contengono lo stesso numero di casi.

Disegno fra soggetti: vedi Disegno tra gruppi.

Disegno misto: vedi ANOVA a disegno misto.

Disegno per dati appaiati: disegno in cui i soggetti sono appaiati rispetto a una covariata o in cui i soggetti fungono da controllo a se stessi. In altre parole, un disegno a misure ripetute o a dati appaiati.

Disegno tra gruppi: disegno sperimentale in cui i soggetti sono assegnati a diversi gruppi o condizioni.

Disegno within-subjects: disegno per prove ripetute o dati correlati.

Distanza euclidea al quadrato: somma delle differenze al quadrato tra i punteggi di due variabili del campione.

Distribuzione campionaria: distribuzione teorica dei parametri di un campione di determinata numerosità se diversi campioni di quella stessa numerosità sono estratti dalla popolazione generale.

Distribuzione chi-quadro: insieme di distribuzioni teoriche di probabilità che variano a seconda dei gradi di libertà e servono per il calcolo della significatività nel test del chi-quadro.

Distribuzione di frequenza: tavola o grafico in cui sono descritte le frequenze con cui si presentano i valori di una variabile.

Distribuzione di probabilità: distribuzione dei punteggi per il solo effetto casuale.

Distribuzione normale: distribuzione definita matematicamente che ha caratteristiche molto importanti. È anche nota come curva a campana. È simmetrica e le due code laterali teoricamente vanno all’infinto, ma questo dal punto di vista applicativo è di modesta importanza.

Effetto principale: effetto di una variabile indipendente, fattore, su una variabile dipendente.

Errore di I tipo: errore che si commette nell’accettare l’ipotesi sperimentale quando in realtà è falsa.

Errore di II tipo: errore che si commette nel rifiutare l’ipotesi sperimentale quando in realtà è vera.

Errore standard: concettualmente il valor medio di quanto differisce la media dei campioni dalla media della popolazione.

Esponente o potenza: un numero con un esponente o potenza viene moltiplicato per se stesso un numero di volte pari al valore dell’esponente. Quindi 32 significa 3 × 3, mentre 43 significa 4 × 4 × 4.

Estrazione: metodo per ottenere i fattori nell’analisi fattoriale.

Eta: misura di associazione per relazioni non lineari.

Etichetta del valore: nome da associare a un valore della variabile. Per esempio “femmina” per il valore “1”.

Etichetta della variabile: etichetta assegnata a una variabile.

Fattore, nell’analisi della varianza: variabile indipendente che corrisponde a un criterio di classificazione o a una condizione sperimentale. La varianza fra gruppi o fra condizioni sperimentali viene analizzata e confrontata nell’ANOVA. Un fattore dovrebbe consistere di una variabile nominale con un contenuto numero di categorie.

Fattore, nell’analisi fattoriale: variabile ottenuta dalla combinazione di più variabili in una combinazione pesata. Il fattore sintetizza la varianza condivisa fra le variabili in una variabile più generale da cui si ipotizza che le variabili siano generate.

Fattori ortogonali: nell’analisi fattoriale, fattori non correlati, indipendenti fra loro.

Finestra dell’output: finestra dello schermo che mostra i risultati dell’analisi.

Finestra di dialogo: finestra rettangolare che permette all’utente di scegliere fra le diverse procedure.

Foglio dati in SPSS: foglio in cui vengono immessi i dati nel programma SPSS.

Frequenza: numero di volte in cui si presenta una determinata condizione.

Funzione discriminante: utilizzata principalmente nell’analisi discriminante. Funzione ottenuta dalla combinazione delle variabili in studio in modo da rendere massima la differenza fra i diversi gruppi all’interno della funzione. Si possono avere diverse funzioni discriminanti ma in questo caso risultano indipendenti fra loro.

Gradi di libertà: il numero di valori che possono variare liberamente senza alterare un valore caratteristico della popolazione come per esempio la media. A parità di altre condizioni, maggiori sono i gradi di libertà più facilmente si otterranno risultati significativi.

Grafico: figura in cui vengono presentati i valori di una o più variabili.

Grafico a barre: grafico in cui le frequenze vengono presentate con barre la cui altezza è proporzionale al valore della frequenza. Sebbene in alcuni casi la frequenza si rappresenti mediante l’area, molti software statistici fra i quali SPSS preferiscono usare semplicemente l’altezza delle barre.

Grafico a linee: diagramma in cui le frequenze di una variabile sono rappresentate da linee.

Grafico a scatole (boxplot): diagramma che indica la distribuzione dei valori di una variabile. Rappresenta la mediana in un rettangolo i cui lati opposti sono gli interquartili superiore e inferiore. Le linee esterne rappresentano i valori estremi.

Grafico di dispersione: grafico che mostra la relazione fra due variabili quantitative. Consiste di un asse orizzontale e uno verticale utilizzati per individuare la posizione di ogni individuo in base al suo valore in ciascuna delle due variabili.

Grafico per l’interazione: grafico che mostra le relazioni fra le medie di due o più variabili.

Grafo: grafico in cui vengono presentate le relazioni (reali o ipotetiche) tra le variabili in studio.

Help: sezione del software che contiene informazioni sulle procedure e il loro utilizzo.

Identificazione: possibilità di stimare i parametri di un modello di equazioni strutturali sulla base dei dati raccolti.

Indice di bontà dell’adattamento: misura della capacità di un particolare modello di prevedere correttamente i dati sperimentali.

Indipendenza statistica: eventi o variabili non correlati fra loro.

Interazione: effetto che descrive i risultati sperimentali che non possono essere attribuiti solo all’influenza separata dei fattori principali. Un effetto interazione si ha quando, per esempio, le variabili hanno effetti significativi se combinate fra loro.

Interquartile: intervallo contenente il 50% centrale di una distribuzione. Ignorando i due quartili estremi, situati in direzioni opposte rispetto alla mediana, l’interquartile è meno influenzato dai valori estremi.

Intervallo di confidenza: un modo più efficiente di rappresentare i risultati di un test rispetto, per esempio, alla semplice media o deviazione standard. Fornisce l’intervallo in cui ci si aspetta che cada il 95% o il 99% delle medie, delle deviazioni standard o di altri parametri statistici calcolati su più campioni della stessa numerosità. Così, per esempio, invece di indicare semplicemente la media di 6.7 si dice che l’intervallo di confidenza al 95% della media sta fra 5.2 e 8.2.

Ipotesi: assunzione che specifica la relazione attesa o predetta fra due o più variabili.

Istogramma: grafico a barre che rappresenta la frequenza dei punteggi o intervalli di punteggi. L’altezza delle barre rappresenta la frequenza del punteggio o dell’intervallo di punteggio.

Lambda di Wilks: misura che utilizza il rapporto fra la somma dei quadrati all’interno dei gruppi e la somma dei quadrati totali, utilizzato per determinare se le medie delle variabili sono significativamente diverse tra i gruppi.

LISREL: nome di un software progettato per effettuare l’analisi di relazioni strutturali lineari, nota come modello a equazioni strutturali.

Livello: usato nell’analisi della varianza per descrivere le differenti condizioni di una variabile indipendente o fattore. Il termine ha avuto origine nella ricerca in agricoltura dove il livello di trattamento corrispondeva alla diversa quantità di fertilizzante utilizzato nella coltura.

Livello alfa: grado di rischio che il ricercatore è disposto ad accettare riguardo all’errore nel respingere l’ipotesi nulla sulla base dei dati disponibili. Generalmente il limite del livello alfa è posto al 5%, cioè 0.05, ed è anche indicato come livello di significatività.

Livello beta: grado di rischio che si è disposti ad accettare per l’errore di non falsificare l’ipotesi nulla nel caso in cui sia falsa.

Livello di misura: distinzione gerarchica a quattro livelli proposta per classificare le misure in nominali, ordinali, a intervalli e di rapporto.

Livello di significatività: livello di probabilità al di sotto del quale si ritiene estremamente improbabile che le differenze ottenute siano dovute al caso.

Log verosimiglianza: indice basato sulla differenza tra le frequenze di una o più variabili categoriche e i valori predetti da un modello. Maggiore il valore del log verosimiglianza, peggiore è l’adattamento del modello ai dati sperimentali.

Logaritmo: numero di volte che una determinata base (es. 10) deve essere moltiplicata per se stessa per dare un dato valore. Nell’espressione 32, che dà come risultato 9, 2 è il logaritmo in base 3. La trasformazione logaritmica viene talvolta utilizzata per trasformare i dati in modo che abbiano le caratteristiche richieste da una data procedura statistica.

Logaritmo naturale o neperiano: logaritmo calcolato usando come base il numero di Nepero 2.718.

Massima verosimiglianza: metodo per stimare i parametri teorici del modello che più probabilmente darebbe origine ai dati osservati.

Matrice: tabella di dati formata da righe e colonne.

Matrice di correlazione: tabella che rappresenta le diverse correlazioni fra tutte le possibili coppie di variabili.

Matrice di varianza-covarianza: matrice contenente sulla diagonale la varianza delle variabili e nelle altre posizioni la covarianza tra ciascuna coppia di variabili.

Media: andamento medio di un punteggio valutato dalla somma dei valori divisa per il numero dei valori. La media di 2 e 3 è 2.5.

Media aggiustata: media stimata dopo aver tolto l’effetto di una o più covariate, usata tipicamente nell’analisi della covarianza.

Media armonica: è data dal numero dei valori sperimentali diviso per il reciproco (1/x) di ogni valore.

Media dei quadrati: termine utilizzato per la stima della varianza nell’analisi della varianza.

Mediana: valore che divide i punteggi in un 50% di valori inferiori e 50% di valori superiori.

Mediatore: variabile che causa la relazione fra altre due variabili.

Metodo per blocchi: metodo della regressione multipla in cui tutti i predittori sono inseriti nell’analisi contemporaneamente.

Metodo per passi: metodo della regressione multipla in cui le variabili vengono inserite nell’equazione una alla volta. In questo caso viene prima inserita la variabile a maggior potere predittivo, poi la seconda a maggior potere predittivo dopo aver tolto quanto già spiegato dalla prima, e così per le rimanenti variabili.

Misura: termine utilizzato in alcuni campi per denotare la variabile dipendente. È la variabile che ci si aspetta cambi al variare dei fattori in studio.

Misura della dispersione: misura della variazione dei punteggi quali la varianza, il range, l’interquartile e l’errore standard.

Moda: picco di frequenza di un valore o di una categoria.

Modello lineare: modello che assume una relazione lineare fra le variabili.

Modello nidificato: un modello che è una parte di un altro modello e che può essere derivato da questo.

Modello saturo: modello (insieme di variabili) che rappresenta completamente i dati. Concetto utilizzato nell’analisi log-lineare.

Moderatore (effetto): situazione in cui la relazione fra due variabili può cambiare per effetto di una terza variabile. La correlazione fra età e stipendio, per esempio, può variare per effetto del genere. Ciò significa che la relazione fra età e stipendio è diversa nei maschi e nelle femmine.

Multicollinearità: si ha quando due o più variabili indipendenti sono fortemente correlate fra loro.

Multimodale: distribuzione di frequenza con tre o più mode.

Multivariata: che include più variabili dipendenti.

Nome della variabile: nome assegnato alla variabile.

Occorrenze: numero di volte (frequenza) in cui si presenta una particolare osservazione (punteggio o categoria, ecc.).

Odds: rapporto fra la probabilità di un evento e la probabilità del non evento.

Odds ratio: valore per cui bisogna moltiplicare l’odds per avere l’incremento di un’unità della variabile predittore.

Omogeneità del coefficiente di regressione: condizione in cui vi è similarità nelle pendenze delle rette di regressione della covariata sulla variabile dipendente nei diversi gruppi del fattore.

Omogeneità delle varianze: condizione in cui le varianze dei punteggi sono simili nei diversi gruppi.

Omoschedasticità: condizione in cui vi è similarità nella dispersione dei punteggi attorno alla retta di regressione in ogni sua parte.

Ordinamento dei casi: procedura di SPSS che permette di ordinare i casi in ragione di una o più variabili.

Ortogonale: dal punto di vista geometrico significa ad angolo retto. Dal punto di vista statistico significa indipendenza, non correlazione.

Outlier: punteggio o dato che differisce sostanzialmente dagli altri valori ottenuti. È un punteggio inusuale, estremamente improbabile per la misura effettuata.

Parametrico: relativo alle caratteristiche della popolazione.

Parametro: valore quale la media o la deviazione standard che si riferisce alla popolazione generale. In contrasto con la statistica del campione che si riferisce solo ai casi esaminati.

Partecipante: che prende parte alla ricerca. Termine più appropriato rispetto a “soggetto”.

PASW: versione di SPSS del 2008-2009.

Pesi: aggiustamento che tiene conto della dimensione della variabile o del campione.

Phi: misura di associazione tra due variabili binomiali o dicotomiche.

Popolazione: l’insieme delle misure di cui il campione è una parte. È un errore pensare alla popolazione come a un insieme di individui perché è la popolazione dei punteggi che ha alcune specifiche caratteristiche.

Potenza: in statistica, la capacità del test di falsificare l’ipotesi nulla quando è falsa.

Promax: metodo di rotazione obliqua nell’analisi fattoriale.

Proprietà di un grafico: in SPSS una finestra che permette di modificare le caratteristiche di un grafico.

Punteggio discriminante: valore individuale prodotto dalla funzione discriminante.

Punteggio z: punteggio espresso come numero di deviazioni standard di distanza dalla media di un campione di riferimento considerato come rappresentativo della popolazione generale.

R2 di Cox e Snell: parte di varianza della variabile dipendente spiegata dai fattori o predittori. Viene utilizzata nella regressione logistica.

Randomizzazione: assegnazione dei casi alle condizioni in studio sulla base di assegnazione casuale.

Range: intervallo fra il valore maggiore e quello minore di una misura.

Rapporto di varianza: rapporto fra due varianze; su questo rapporto è basata l’analisi della varianza.

Rapporto di verosimiglianza (test chi-quadro per): tipo di test chi-quadro che utilizza i logaritmi naturali. È utilizzato principalmente nell’analisi log-lineare.

Rapporto F: rapporto di due varianze. Può essere usato per verificare se due varianze differiscono significativamente fra loro attraverso la relativa distribuzione F. Può essere usato autonomamente ma è parte centrale dell’ANOVA.

Regressione gerarchica o sequenziale: tipo di regressione in cui l’ordine di inclusione delle variabili dipendenti (predittori) è definito dall’utente e non da criteri matematici o statistici.

Regressione logistica: regressione multipla in cui la variabile dipendente è nominale. I fattori possono essere indifferentemente variabili quantitative o nominali. Può inoltre considerare fra i predittori l’effetto interazione fra variabili qualitative e quantitative. La procedura fa largo uso di variabili fittizie.

Regressione multipla: test parametrico per stimare il legame fra due o più predittori (variabili indipendenti) e una variabile dipendente. Viene stimato tenendo conto della relazione fra i predittori. Può inoltre essere incluso nel modello anche l’effetto dovuto all’interazione fra i predittori.

Regressione semplice: test che analizza il grado e la direzione dell’associazione fra due variabili quantitative, un predittore e una variabile dipendente.

Relazione lineare: relazione fra due serie di valori rappresentabile da una linea retta. La dispersione dei dati viene meglio rappresentata da una linea retta che da una curva.

Residuo: differenza fra valori attesi e valori osservati.

Ricerca quantitativa: ricerca che quasi non contempla il semplice conteggio delle frequenze delle categorie per la principale variabile in studio.

Ricodifica: trasformazione di un valore in un altro secondo un certo criterio, per esempio la variabile età ricodificata nella variabile classe di età.

Selezione casi: procedura di SPSS per selezionare un sotto-campione di casi in base ad alcuni criteri quali, per esempio, il genere.

Sezione dati: foglio di SPSS contenente i dati in uso.

Sfericità: condizione nella quale sussistono correlazioni simili tra le misure della variabile dipendente nelle diverse situazioni sperimentali.

Significatività nei confronti multipli, FWER (family-wise error rate): probabilità di commettere almeno un errore di scorretta falsificazione dell’ipotesi nulla quando vengono fatti più confronti sugli stessi dati sperimentali.

Sintassi: comandi o istruzioni utilizzate per eseguire le diverse procedure software.

Skew: caratteristica di una distribuzione di frequenza in cui i punteggi tendono a formare una sola coda. In altre parole, rappresenta una distribuzione di frequenza asimmetrica, diversa dalla distribuzione gaussiana (con forma a campana).

Somma dei quadrati: somma delle differenze, elevate al quadrato, fra ciascun punteggio e la media dei punteggi. La “media” di questi valori è la varianza.

Somma dei quadrati dei residui: somma dei quadrati rimanenti dopo che tutte le sorgenti di varianza sono state rimosse.

Sottogruppo: gruppo di casi appartenenti all’intersezione di una variabile categorica con altre variabili categoriche. Se una variabile ha categorie A, B e C e l’altra variabile ha categorie X, Y e Z, i sottogruppi sono formati dai casi appartenenti ad A e X, A e Y, A e Z, B e X, B e Y, ecc. È utilizzato nell’ANOVA e nelle tavole di contingenza.

SPSS: pacchetto di software per l’analisi statistica dei dati.

Statistica descrittiva: insieme di indici o parametri che descrivono le principali caratteristiche delle variabili o le loro relazioni. Include le misure di tendenza centrale (per esempio media, mediana e moda) e misure di dispersione (minimo e massimo, varianza ecc.).

Statistica di Wald: rapporto fra i coefficienti beta e il loro errore standard. Viene usata nella regressione logistica.

Statistica inferenziale: insieme di tecniche statistiche che servono a predire le caratteristiche della popolazione generale sulla base delle caratteristiche del campione.

Stima della varianza: la varianza della popolazione generale stimata sulla base della varianza del campione estratto da quella stessa popolazione.

t-test per dati indipendenti: test parametrico per valutare se le medie di due gruppi indipendenti sono significativamente diverse fra loro.

Tabella pivot: tabella di SPSS che può essere modificata.

Tau di Kendall: coefficiente di associazione tra due variabili ordinali. Un coefficiente di correlazione per dati non parametrici.

Tavole di contingenza: tavole di frequenza che forniscono la frequenza di casi in ciascuna delle possibili combinazioni di due o più variabili nominali (categoriche).

Test a due code: test che calcola la significatività di una relazione o di una differenza in entrambe le direzioni.

Test a una coda: una versione del test di significatività in cui vi è una forte ragione per ipotizzare che le differenze possano essere solo in una direzione. Tale ipotesi deve essere supportata da ottime ragioni teoriche e sperimentali. L’ipotesi di unidirezionalità deve essere inoltre formulata prima dell’esperimento.

Test a priori: un test sulla differenza fra punteggi quando il confronto viene pianificato prima di conoscere i dati sperimentali. Questo tipo di confronto è il contrario del test post hoc, che viene effettuato dopo aver raccolto i dati in assenza di particolari ipotesi sul risultato atteso.

Test del chi-quadro di Pearson: un test di bontà dell’adattamento o di associazione per frequenze. Confronta i dati osservati con quelli stimati (o teorici) della popolazione globale (si basa in genere su due o più campioni).

Test del segno: test non parametrico che valuta se differisce significativamente il numero di differenze positive dal numero di differenze negative.

Test di Bartlett (test di sfericità): test usato nella MANOVA per verificare se le correlazioni fra le variabili sono significativamente diverse da zero.

Test di Fisher: test esatto di significatività nelle tavole di contingenza 2 × 2 o 2 × 3.

Test di Friedman: test non parametrico per verificare se tre o più medie dei ranghi, relative a diverse condizioni sperimentali, differiscono significativamente fra loro.

Test di Kolmogorov-Smirnov: test non parametrico per verificare se la distribuzione dei valori di una variabile ordinale differisce significativamente in due campioni indipendenti.

Test di Kruskal-Wallis: test non parametrico per determinare se le medie dei ranghi per tre o più campioni indipendenti differiscono significativamente.

Test di Levene: analisi della varianza sulle differenze assolute per determinare se le varianze di due o più gruppi indipendenti differiscono significativamente fra loro.

Test di Mann-Whitney: test non parametrico per valutare se le medie dei ranghi di due gruppi indipendenti sono significativamente diverse fra loro.

Test di Mauchly: test per valutare se è violata l’assunzione, nell’analisi della varianza per prove ripetute, che la matrice di varianza-covarianza sia sferica.

Test di McNemar: test per valutare se c’è stata una variazione significativa nelle frequenze di due categorie misurate con due diversi metodi sugli stessi casi.

Test di Scheffé: test post hoc usato nell’analisi della varianza per verificare se due medie di gruppo differiscono fra loro significativamente.

Test di Wilcoxon: test non parametrico per stabilire se i punteggi ottenuti su un campione in due prove ripetute sono significativamente diversi.

Test non parametrico: test statistico che sulla distribuzione di probabilità dei punteggi richiede meno assunzioni riguardanti la distribuzione dei valori campionari rispetto a un test parametrico.

Test parametrico: test statistico che parte dall’assunzione che i punteggi utilizzati siano relativi ai punteggi della popolazione generale e che questi abbiano una distribuzione normale.

Test post hoc: test per vedere se due gruppi differiscono significativamente quando nell’esperimento il ricercatore non ha motivate ragioni per aspettarsi un risultato specifico.

Test Q di Cochran: serve per saggiare se le frequenze di una variabile dicotomica differiscono significativamente in più di due gruppi o dati correlati.

Totali marginali: totali di riga e di colonna in una tavola di contingenza.

Trasformazione: tecnica per trasformare i dati in modo che ottemperino all’assunzione di una procedura statistica. Per esempio, i dati possono essere trasformati nella loro radice quadrata, nel loro logaritmo o altro. Più tentativi possono essere necessari per ottenere una trasformazione opportuna.

Trattamento dei dati: varie tecniche per la trasformazione di dati sperimentali che non includano analisi statistiche. Può comprendere l’immissione di dati, la ricerca di errori, la ricodifica dei valori, il calcolo di nuove variabili e altre operazioni simili.

Univariata: riguardante una sola variabile dipendente.

V di Cramer: noto anche come phi di Cramer, coefficiente di associazione utilizzato nelle tavole di contingenza con più di 2 righe e 2 colonne.

Valore critico: utilizzato per valutare la significatività statistica con tabelle delle distribuzioni come quelle riportate in Appendice. Rappresenta il valore minimo del parametro statistico in base al quale è possibile falsificare l’ipotesi nulla, ovvero al di sotto del quale i risultati sono significativi.

Variabile categorica: variabile nominale, qualitativa, relativa a categorie, non a quantità. Può essere indicata da numeri che hanno tuttavia il valore di etichette.

Variabile confondente: variabile che rende problematica l’interpretazione della correlazione o di altra relazione statistica. Togliendo l’effetto della variabile confondente, la relazione che si ottiene permette un’immagine più realistica della relazione fra le variabili.

Variabile di gruppo: variabile che definisce l’appartenenza di un soggetto o di un valore a un gruppo o a una particolare condizione sperimentale.

Variabile di rapporto: misura in cui ha senso dire che un punteggio è multiplo di un altro, come 20 è il doppio di 10. Deve anche includere un valore zero di riferimento. Questa è la variabile ideale per i calcoli statistici che lo psicologo quasi mai incontra a meno che si tratti di misura del tempo o della distanza.

Variabile dipendente: variabile che si ritiene venga influenzata o predetta da altre variabili in studio.

Variabile dummy o variabile fittizia: utilizzata nell’analisi di dati nominali (categorici) per permetterne l’utilizzo in modo analogo alle variabili quantitative. Ogni categoria della variabile nominale è trasformata in una diversa variabile fittizia. Se, per esempio, la variabile è formata da tre categorie A, B e C, saranno create tre nuove variabili: la prima per i valori A o non A, la seconda per i valori B o non B, la terza per i valori C o non C. Le variabili fittizie possono quindi essere codificate 0 o 1. Nel caso in cui le categorie siano solo due in alternativa, la variabile fittizia è una sola, con i valori 0 o 1.

Variabile endogena: nella path analysis è una variabile che può essere spiegata sulla base di una o più variabili in studio.

Variabile esogena: nella path analysis è la variabile che non può essere spiegata da nessuna delle altre variabili in studio.

Variabile fittizia: variabile creata per la codifica fittizia di variabili nominali.

Variabile indipendente: variabile che può influenzare (predire) il valore di una o più altre variabili. Viene utilizzata per indicare i gruppi nei disegni sperimentali. Viene anche utilizzata nella regressione per indicare la variabile in grado di predire il valore della variabile dipendente.

Variabile latente: variabile non osservata, generata da una o più variabili manifeste, dette indicatori.

Variabile manifesta: variabile rappresentata direttamente dalla misura utilizzata per valutarla.

Variabili: finestra di SPSS che mostra l’elenco delle variabili, il loro nome e il tipo.

Variabili numeriche: variabili che vengono raccolte come punteggi che indicano una quantità.

Varianza: valore atteso della somma delle differenze al quadrato tra ciascun punteggio e la media generale. È una misura della variabilità dei punteggi.

Varianza comune: la parte di varianza condivisa da due o più variabili.

Varianza unica: varianza di una variabile che non condivide con le altre variabili in analisi.
